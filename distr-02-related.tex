
\newcommand{\Vertices}{\ensuremath{\cV{}}\xspace}
\newcommand{\Edges}{\ensuremath{\cE{}}\xspace}
\newcommand{\Heldout}{\ensuremath{\cE_h{}}\xspace}
\newcommand{\SGLDMinibatch}{\ensuremath{\cD_n{}}\xspace}
\newcommand{\Minibatch}{\ensuremath{\cE_n{}}\xspace}
\newcommand{\Minibatcht}{\ensuremath{\cE_n{}}\xspace}
\newcommand{\Neighbors}{\ensuremath{\cV_n{}}\xspace}

\section{Background}
% In this section, we briefly review the Bayesian model we are considering in this paper.

% In this section, we briefly review the Bayesian model we are considering in this paper.
\subsection{Assortative Mixed-membership Stochastic Blockmodels (a-MMSB)}
The assortative mixed membership stochastic blockmodel (a-MMSB)~\cite{gopalan2012scalable} is a special case of MMSB~\cite{airoldi2009mixed} that models the group structure in a network of $N$ vertices. Consider a set  \Vertices containing all the vertices in the graph, and a set \Edges containing all the linked edges between pairs of vertices. Each vertex $a$ in the vertex set \Vertices has a $K$-dimensional probability distribution $\pi_a$ of participating in the $K$ members of the community set $\cK$.  For every possible peer $b$ in the network, each vertex $a$ randomly draws a community $z_{ab}$. If a pair of vertices ($a,b$) in the edge set \Edges are in the same community, i.e., $z_{ab}=z_{ba} = k$, then they have a significant probability $\bt_k$ to connect, i.e., $y_{ab}=1$. Otherwise this probability is a small value $\dt$. Each community has its connection strength $\beta_{k} \in (0,1)$ which reflects how likely its members are linked to each other. The whole generative process of a-MMSB is then described by:
\benum
\item For each community $k$, draw community strength $\bt_k \sim \mbox{Beta}(\eta)$
\item For each vertex $a$, draw community memberships $\pi_a \sim \mbox{Dirichlet}(\al)$
\item For each pair of vertices $a$ and $b$,
\benum
	\item Draw interaction indicator $z_{ab} \sim \pi_a$
    \item Draw interaction indicator $z_{ba} \sim \pi_b$
    \item Draw link $y_{ab} \sim \mbox{Bernoulli}(r)$, where $r = \bt_k$ if $z_{ab}=z_{ba}=k$, and $r=\dt$ otherwise.
\eenum
\eenum
$\eta$ and $\alpha$ are parameters to the Beta and Dirichlet distribution functions.

\subsection{Stochastic Gradient Markov Chain Monte Carlo}
The algorithm we are working on in this paper is based on stochastic gradient Langevin dynamics (SGLD)~\cite{welling2011bayesian}. SGLD applies the following update rule to obtain samples from a posterior distribution $p(\ta|\cX) \propto p(\cX|\ta) p(\ta)$ of $N$ i.i.d. data points $\cX=\{x_i\}_{i=1}^{N}$:
\bea
\ta^* \law \ta + \f{\epsilon_t}{2}\left(\nabla_{\ta}\log p(\ta_t)+N\bar{g}(\ta;\SGLDMinibatch)\right) + \xi_t, \label{eqn:sgld_update}
\eea
where $\xi_t \sim \cN(0,\epsilon_t )$ with $\ep_t$ the step size, $\SGLDMinibatch$ a mini-batch of size $n$ sampled from $\cX$, and $\bar{g}(\ta;\SGLDMinibatch)$ the mean stochastic gradient, i.e., $\frac{1}{|\SGLDMinibatch|}\sum_{x\in \SGLDMinibatch}^{}\grad_{\ta} \log p(x|\ta)$. As the step size goes to zero by a schedule satisfying $\sm{t}{\infty}\ep_t = \infty$ and $\sm{t}{\infty}\ep_t^2 < \infty$, SGLD samples from the true posterior distribution. One benefit of using SGLD is that we do not need the Metropolis-Hastings (MH) accept-reject tests since the rejection probability goes to zero as the step size tends to zero. Although in practice we often do not reduce the stepsize to zero to obtain better mixing (thus resulting in some bias), we obtain good performance by drawing many more samples per unit time. 

SGLD originated from the Langevin Monte Carlo (LMC)~\cite{girolami2011riemann}, where unlike SGLD the gradient is computed exactly by using all data points. Then, Metropolis-Hastings accept-reject tests are applied. Comparing to LMC, SGLD only requires to process a mini-batch $\SGLDMinibatch$ at each iteration and ignores the MH test, and thus the computation complexity substantially reduces from $\cO(N)$ to $\cO(n)$.   

Stochastic gradient Riemannian Langevin dynamics (SGRLD)~\cite{patterson2013stochastic} is a subclass of SGLD which is developed to efficiently sample from the probability simplex. By applying Riemannian geometry~\cite{girolami2011riemann} and using the mini-batch-based estimator in Eq.~\ref{eqn:sgld_update}, it achieved state-of-the-art performance for latent Dirichlet allocation (LDA)~\cite{blei2003latent}. In particular, for a $K$-dimensional probability simplex $\pi$, it uses the \textit{expanded-mean} re-parameterization trick, where the probability of a category $k$ is given by $\pi_k = \ta_k / \sum_{j=1}^K \ta_j$ with $\ta_k \sim \text{Gamma}(\al,1)$ and $\al$ a hyperparameter of the Dirichlet distribution $p(\pi | \al )$. Then, the update rule of SGRLD is:
\bea
\ta_{k}^* \law \left| \ta_{k} + \f{\ep_t}{2} \left( \al - \ta_{k} + \f{N}{|\SGLDMinibatch|} \sum_{d \in \SGLDMinibatch} g_d(\ta_{k}) \right) + (\ta_{k})^\ha \xi_{t} \right|, \label{eqn:sgrld_update}
\eea
here $g_d(\ta_{k})$ is the gradient of the log posterior w.r.t. $\ta_{k}$ on a data point $d\in \SGLDMinibatch$.


\subsection{Scalable MCMC for a-MMSB}
This section describes the SG-MCMC algorithm for a-MMSB. Please refer to~\cite{LiAW15} for more details. The algorithm iterates updating local parameter $\pi$ and global parameter $\beta$. Since both parameters lie on the probability simplex, SGRLD is applied to make the sampling process more efficient. Here, the parameters $\phi$ and $\ta$ are used to re-parameterize $\pi$ and $\beta$ respectively. After updating $\phi$ and $\ta$, we can obtain $\pi$ and $\beta$ by normalizing $\phi$ and $\ta$ respectively, see Table~\ref{tbl-symbols}. In the following, we briefly sketch the iterative update steps.

\paragraph{\textbf{Sampling global parameters}} The update rule for global parameter $\theta$ is
\bea
\ta_{ki}^* \law \left| \ta_{ki} + \f{\ep}{2} \left( \eta - \ta_{ki} + h(\Minibatcht)\sum_{(a,b) \in \Minibatcht}g_{ab}(\ta_{ki})\right) \right.\nn \\ \left.+ (\ta_{ki})^{\ha}\xi_{ki} \right|, \label{eqn:global_update}
\eea
where the gradient in $\theta$ is
\bea
g_{ab}(\ta_{ki})
&=& \f{f_{ab}^{(y)}(k,k)}{Z_{ab}^{(y)}} \left(\f{|1-i-y|}{\ta_{ki}} - \f{1}{\sum_j\ta_{kj}} \right),
\eea
here $\Minibatcht$ is a mini-batch of $n_t$ vertex pairs sampled from $\Edges$ or $E$; $h(\Minibatcht)$ is a weight factor to scale the effect of a mini-batch towards the full network; and 
\bea
f_{ab}^{(y)}(k,l)=
\begin{cases}
\bt_k^y(1-\bt_k)^{(1-y)}\pi_{ak}\pi_{bk}, & \mbox{if } k=l\\
\dt^{y}(1-\dt)^{(1-y)} \pi_{ak} \pi_{bl}, & \mbox{if } k \neq l \nn.
\end{cases}
\label{eqn:case}
\eea
$Z_{ab}^{(y)}$ is the normalization constant which we can compute in $\cO(K)$ time \cite{LiAW15}.

\paragraph{\textbf{Sampling local parameters}}
The update rule for the local parameters $\phi$ is
\bea
\phi_{ak}^* \law \left| \phi_{ak} + \f{\ep}{2} \left( \al - \phi_{ak} + \f{N}{|\Neighbors|} \sum_{b \in \Neighbors} g_{ab}(\phi_{ak})\right) \right. \nn \\ \left. + (\phi_{ak})^{\ha} \xi_{ak}\right|,
\label{eqn:local_update}
\eea
where the gradient in $\phi$ is
\bea
g_{ab}(\phi_{ak}) = \f{f_{ab}^{(y)}(k)}{Z_{ab}^{(y)}\phi_{ak}} - \f{1}{\sum_j\phi_{aj}}.
\eea
Here, $\Neighbors$ is the neighbor set for a mini-batch node, another random mini-batch of $n$ nodes sampled from \Vertices. Note that $|\Neighbors| \ll |\Vertices|=N$.

As is common in machine learning problems, the edges of the graph are divided
into two sets, the training set and a held-out set \Heldout.
As the performance metric we use perplexity, which is defined as the exponential
of the negative average log-likelihood of the held-out set \Heldout. Given a collection of $T$
samples of the model parameters $\{\bt_t\}$ and $\{\pi_t\}$, the averaged
perplexity on the held-out set $\Heldout$ is 
\begin{align}
&\text{perp}_{\text{avg}}(\Heldout|\{\beta_t\},\{\pi_t\})\nonumber \\=&
\exp\left(-\frac{\sum_{(a,b)\in \Heldout}^{}\log
\{(1/T)\sm{t}{T}p(y_{ab}|\beta_t,\pi_t)\}}{|\cE_{h}|}\right).
\end{align}
The perplexity is not evaluated at every iteration, but at regular intervals.
Convergence is reached when the perplexity changes by less than a small
threshold.

The pseudo-code of the sequential algorithm is presented in Algorithm~\ref{algorithm}. 

\begin{algorithm}[t]
\caption{Sequential version of SG-MCMC for a-MMSB}\label{alg}
\begin{algorithmic}[1]
\STATE Initialize $\pi , \bt, \phi, \ta$
\WHILE {sampling}
\STATE Sample mini-batch of vertex pairs \Minibatch from \Edges or $E$
\FOR {each vertex in \Minibatch}
    \STATE Sample mini-batch of vertices $\Neighbors$ from $\Vertices$
    \STATE Update $\phi_{a}$ using Eq.~\ref{eqn:local_update}
  %  $\phi_{a}^* \law \left| \phi_{a} + \f{\ep_{\phi}}{2} \left( \al - \phi_{a} + \f{N}{|\Neighbors|} \sum_{b \in \Neighbors} G_{\phi_{a}}\right) + (\phi_{a})^{\ha} \xi_{a}\right|$
    \STATE Obtain $\pi_a$ from $\phi_a^*$ \ENDFOR
\FOR {$k = 1,\dots,K$}
    \STATE Update $\ta_{k}$ using Eq.~\ref{eqn:global_update}
   % $\ta_{k}^* \law \left| \ta_{k} + \f{\ep_\ta}{2} \left( \eta - \ta_{k} + h(\cE_t) \sum_{(a,b) \in \cE_t} G_{\ta_{k}}(a,b) \right) + (\ta_{k})^{\ha}\xi_{k} \right|$
    \STATE Obtain $\bt_k$ from $\ta_k^*$
\ENDFOR
\ENDWHILE
\end{algorithmic}
\label{algorithm}
\end{algorithm}


\addtolength{\tabcolsep}{-3pt}
\renewcommand{\arraystretch}{1.5}
\begin{table}[b] % [htbp]
\center
\begin{tabular}{c C{0.075\textwidth} c L{0.26\textwidth}}
\textbf{symbol}
	 & \textbf{type} & \textbf{size} & \textbf{description} \\
         % & \multicolumn{1}{c}{\textbf{type}}
                           % & \multicolumn{1}{c}{\textbf{description}} \\
\hline
$\cK$      &              & $K$        & set of communities \\
\Vertices  & \{vertex\}   & $N$          & vertices in the graph \\
\Edges     & \{edge\}     &              & linked edges in the graph \\
$E$        & \{edge\}     &              & $\Vertices\times\Vertices$: linked and nonlinked edges \\
\Heldout   & \{edge\}     &              & held-out subset of the graph \\
\Minibatch & \{edge\}     &              & sampled mini-batch of edges in~$E$ \\
$M$        &              &              & number of vertices in \Minibatch \\
\Neighbors & \{vertex\}   &              & sampled neighbor set for a vertex in~\Minibatch \\
$\theta$   & float~vector 2-D & $K\times{}2$ & reparameterization of $\beta$.
					$\beta[k] = \theta[k][1] / \sum_j\theta[k][j]$ \\
$\beta$    & float vector & $K$          & community strength \\
$\phi$     & float~vector 2-D & $N\times{}K$ & reparameterization of $\pi$.
					$\pi[i][k] = \phi[i][k] / \sum_j\phi[i][j]$ \\
$\pi$      & float~vector 2-D & $N\times{}K$ &
					$\pi[i][k]$~is~probability that vertex $i$ is in community $k$ \\
\hline
\end{tabular}
\caption{Definition of most important symbols}
\label{tbl-symbols}
\end{table}
\addtolength{\tabcolsep}{3pt}
\renewcommand{\arraystretch}{1.0}

\begin{comment}
Assortative mixed-membership stochastic blockmodel (a-MMSB) [1] is a special case of MMSB [8] that models the group-structure in a network of $N$ nodes. In particular, each node $a$ in the node set \Vertices has a $K$-dimension probability distribution $\pi_a$ of participating in the $K$ members of the community set $\cK$. For every possible peer $b$ in the network, each node $a$ randomly draws a community $z_{ab}$. If a pair of nodes ($a,b$) in the edge set \Edges are in the same community: $z_{ab}=z_{ba} = k$, then they have a significant probability $\bt_k$ to connect, i.e., $y_{ab}=1$. Otherwise this probability is small. Each community has its connection strength $\beta_{k} \in (0,1)$ which explains how likely its members are linked to each other.  

The generative process of a-MMSB is then given by,

\benum
\item For each community $k$, draw community strength $\bt_k \sim \mbox{Beta}(\eta)$
\item For each node $a$, draw community memberships $\pi_a \sim \mbox{Dirichlet}(\al)$
\item For each pair of nodes $a$ and $b$,
\benum
	\item Draw interaction indicator $z_{ab} \sim \pi_a$
    \item Draw interaction indicator $z_{ba} \sim \pi_b$
    \item Draw link $y_{ab} \sim \mbox{Bernoulli}(r)$, where $r = \bt_k$ if $z_{ab}=z_{ba}=k$, and $r=\dt$ otherwise.
\eenum
\eenum

Unlike the a-MMSB, the original MMSB maintains pair-wise community strength $\bt_{k,k'}$ for all pairs of the communities. Note that it is trivial to extend the results that we obtain in this paper to the general MMSB model. The joint probability of the above process can be written as:
\begin{align}
p(y,z,\pi ,\bt | \al, \eta) &= \prod_{a=1}^{N} \prod_{b > a}^{N} p(y_{ab} | z_{ab}, z_{ba}, \bt) p(z_{ab}|\pi_a)\nonumber \\ &p(z_{ba}|\pi_b) \pd{a}{N}p(\pi_a|\al) \pd{k}{K} p(\bt_k|\eta).\label{eqn:joint}
\end{align}

Both variational inference [1,4,16] and collapsed Gibbs sampling algorithms [11] have been used successfully for small to medium scale problems. However, the $\cO(N^2)$ computational complexity per update prevents it from being applied to large scale networks. A stochastic variational algorithm was developed in [1] to address this issue, where each update only depends on a small mini-batch of the nodes in the network. 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Stochastic Gradient MCMC Algorithms}
Our algorithm will be based on the stochastic gradient Langevin dynamics (SGLD) [3]. To sample from a posterior distribution $p(\ta|\cX) \propto p(\cX|\ta) p(\ta)$ given $N$ i.i.d. data points $\cX=\{x_i\}_{i=1}^{N}$, SGLD applies the following update rule:
\bea
\ta^* \law \ta + \f{\epsilon_t}{2}\left(\nabla_{\ta}\log p(\ta_t)+N\bar{g}(\ta;\SGLDMinibatch)\right) + \xi, \label{eqn:sgld_update}
\eea
where $\xi \sim \cN(0,\epsilon_t )$ with $\ep_t$ the step size, $\SGLDMinibatch$ a mini-batch of size $n$ sampled from $\cX$, and $\bar{g}(\ta;\SGLDMinibatch) = \frac{1}{|\SGLDMinibatch|}\sum_{x\in \SGLDMinibatch}^{}\grad_{\ta} \log p(x|\ta)$. As the step size goes to zero by a schedule satisfying $\sm{t}{\infty}\ep_t = \infty$ and $\sm{t}{\infty}\ep_t^2 < \infty$, SGLD samples from the true posterior distribution. In SGLD, the Metropolis-Hastings (MH) accept-reject tests are ignored since the rejection probability goes to zero as the step size collapses to zero. While for a finite step size this results in some bias, the overall error is reduced by the reduction of variance due to the ability to draw many more samples per unit time. 

SGLD originated from the Langevin Monte Carlo (LMC) [15] where, unlike SGLD, the gradient is computed exactly using all data points and then a Metropolis-Hastings accept-reject test is applied. Because at each iteration SGLD requires to process only a mini-batch $\SGLDMinibatch$ and ignores the MH test, the computation complexity per iteration is only $\cO(n)$ as opposed to $\cO(N)$ of LMC. Any mini-batch sampling algorithm in the form of Eq.~\eqref{eqn:sgld_update} is called valid SGLD as long as it guarantees the gradient estimator to be unbiased, i.e.,
$\eE_{\SGLDMinibatch} \left[N\bar{g}(\ta;\SGLDMinibatch)\right] = \grad_{\ta} \log p(\cX|\ta)\label{eqn:sgld_grad_estm}$ and the variance to be finite [5].

%%%%%%%%%%%%%%
%\subsection{Stochastic Gradient Riemannian Langevin Dynamics (SGRLD)}

The stochastic gradient Riemannian Langevin dynamics (SGRLD) [2] is a subclass of SGLD which is developed to sample from the probability simplex. By applying Riemannian geometry [15] and using the mini-batch estimator in Eq.~\ref{eqn:sgld_update}, it achieved state-of-the-art performance for latent Dirichlet allocation (LDA). In particular, for a $K$-dimensional probability simplex $\pi$, it uses the \textit{expanded-mean} re-parameterization trick, where the probability of a category $k$ is given by $\pi_k = \ta_k / \sum_{j=1}^K \ta_j$ with $\ta_k \sim \text{Gamma}(\al,1)$ and $\al$ a hyperparameter of the Dirichlet distribution $p(\pi | \al )$.
Then, the update rule becomes

%==============================================================

\bea
\ta_{k}^* \law \left| \ta_{k} + \f{\ep}{2} \left( \al - \ta_{k} + \f{N}{|\SGLDMinibatch|} \sum_{d \in \SGLDMinibatch} g_d(\ta_{k}) \right) + (\ta_{k})^\ha \xi_{} \right|. \label{eqn:sgrld_update}
\eea
here $g_d(\ta_{k})$ is the gradient of the log posterior w.r.t. $\ta_{k}$ on a data point $d\in \SGLDMinibatch$.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Scalable MCMC for a-MMSB}
Our algorithm iterates updating local parameters $\pi$ and a global parameter $\beta$. Because both parameters lie on the probability simplex, we start from the SGRLD and modify it to be more efficient. Also, we introduce parameters $\phi$ and $\ta$ to re-parameterize $\pi$ and $\beta$ respectively. Thus, we alternatingly sample in the $\phi$ and $\ta$ spaces, and then obtain $\pi$ and $\beta$ by normalizing $\phi$ and $\ta$. From Eq.~\ref{eqn:joint}, summing over the latent variable $z$, we obtain the following joint probability,
\bea
&p(y, \pi , \bt | \al , \eta) = \prod_{a} p(\pi_a | \al ) + \prod_{a} p(\bt_k | \eta)\nn \\
&+ \prod_{a} \prod_{b > a}\sum_{z_{ab}, z_{ba}} p(y_{ab}, z_{ab}, z_{ba} | \bt , \pi_a, \pi_b)
\label{eqn:log_joint}.
\eea


%==============================================================
\subsection{Sampling the global parameter}

By the re-parameterization, we have $\beta_k=\ta_{k1}/(\ta_{k0}+\ta_{k1})$, where $\ta_{ki}\sim$ Gamma$(\eta)\propto \ta_{ki}^{\eta-1}e^{-\ta_{ki}}$. Because $p(y, \pi , \bt | \al , \eta)$ decomposes into $p(y,\bt|\pi,\eta) p(\pi|\al)$, replacing $\bt$ by $\ta$, we compute the derivative of log of Eq.~\ref{eqn:log_joint} w.r.t. $\ta_{ki}$ for $i=\{0,1\}$ as follows:
\bea
\fp{\ln p(y ,\ta | \pi, \eta )}{\ta_{ki}} =
\fp{}{\ta_{ki}} \ln p(\ta_{ki} | \eta) + \sum_{a}\sum_{b>a} g_{ab}(\ta_{ki}),
\label{eqn:grad_bt}
\eea
where $g_{ab}(\ta_{ki}) = \fp{}{\ta_{ki}} \ln \sum_{z_{ab},z_{ba}} p(y_{ab},z_{ab},z_{ba} | \ta , \pi_a, \pi_b)$ which, similar to SGRLD for LDA [2], we can rewrite as
\bea
g_{ab}(\ta_{ki}) = \eE \left[ \eI[z_{ab}=z_{ba}=k] \left( \f{|1-i-y_{ab}|}{\ta_{ki}} - \f{1}{\ta_{k}} \right)\right]. \label{eqn:G}
\eea
where $\ta_{k}=\sum_i \ta_{ki}$ and $\eI[S]$ is equal to $1$ if a condition $S$ is TRUE and $0$ otherwise. The expectation is w.r.t. the posterior distribution of latent variables $z_{ab}$ and $z_{ba}$,
\bea
&&p(z_{ab}=k,z_{ba}=l | y_{ab}, \pi_a, \pi_b, \bt )\\ &&\propto f_{ab}^{(y)}(k,l)=
\begin{cases}
\bt_k^y(1-\bt_k)^{(1-y)}\pi_{ak}\pi_{bk}, & \mbox{if } k=l\\
\dt^{y}(1-\dt)^{(1-y)} \pi_{ak} \pi_{bl}, & \mbox{if } k \neq l \nn
\end{cases}
\label{eqn:case}
\eea
here we used simple notation $y$ instead of $y_{ab}$. Unlike the SGRLD for LDA [2], we compute the expectation in Eq.~\eqref{eqn:G} analytically by computing the normalization constant $Z_{ab}^{(y)} = \sm{k}{K}\sm{l}{K} f_{ab}^{(y)}(k,l)$ which can be reduced to $\cO(K)$ computation as follows
\begin{align}
&Z_{ab}^{(y)} = \dt^{y}(1-\dt)^{(1-y)} \nonumber\\&+\sm{k}{K} \left( \bt_k^{y}(1-\bt_k)^{(1-y)} - \dt^{y}(1-\dt)^{(1-y)}\right)\pi_{ak}\pi_{bk}
\end{align}

Then Eq.~\eqref{eqn:G} becomes
\bea
g_{ab}(\ta_{ki}) 
&=& \f{f_{ab}^{(y)}(k,k)}{Z_{ab}^{(y)}} \left(\f{|1-i-y|}{\ta_{ki}} - \f{1}{\ta_k} \right).
\eea
Plugging this into Eq.~\ref{eqn:sgrld_update}, we obtain the update rule for the global parameter,

\bea
\ta_{ki}^* \law \left| \ta_{ki} + \f{\ep}{2} \left\{ \eta - \ta_{ki} + h(\Minibatcht)\sum_{(a,b) \in \Minibatcht}g_{ab}(\ta_{ki})\right\} \right.\nn \\ \left.+ (\ta_{ki})^{\ha}\xi_{ki} \right|, \label{eqn:global_update}
\eea
here $\Minibatcht$ is a mini-batch of $n_t$ node pairs sampled from \Edges for which we use the following strategy.

\textbf{Stratified sampling:} considering that the number of links is much smaller than that of non-links, we can reduce the variance of the gradient using stratified sampling, similar to the method used in [1]. For this, at every iteration we first randomly select a node $a$ and then toss a coin with probability 0.5 to decide whether to sample link edges or non-link edges for node $a$. If it is a link, we assign all of the link edges of node $a$ to $\cE_n$. Otherwise, i.e. if it is non-link, we uniformly sample a mini-batch of $N/m$ non-link edges from the entire set of non-link edges and assign it to $\cE_n$. Here, the $m$ is a hyper-parameter. Note that the size of $|\cE_n|$ will thus be much smaller than the total number of $N(N-1)/2$ edges when $m$ is reasonably large. Then, to ensure that the gradient is unbiased, a \textit{scaling parameter} $h(\cE_n)$ is multiplied. Specifically, $h(\cE_n)$ is set to $N$ when $\cE_n$ is a set of link edges and to $mN$ otherwise. 

Because the global parameters $\{\beta_k\}$ does not change very fast compared to the local parameters $\{\pi_{ak}\}$, in practice we update only a random subset of the $\{\beta_k\}$ at each iteration.

\subsection{Sampling the local parameters}

Similar to the global parameter, we re-parameterize the local parameter $\pi_a$ such that $\pi_{ak} = \phi_{ak} / \sum_{j=1}^{K}\phi_{aj}$, with $\phi_{ak}\sim$ Gamma$(\alpha)\propto \phi_{ak}^{\alpha-1}e^{-\phi_{ak}}$. Then, taking the derivative of the log of Eq.~\ref{eqn:log_joint} w.r.t. $\phi_{ak}$, we obtain
\bea
\fp{\ln p(y , \phi | \bt, \al)}{\phi_{ak}} = \fp{}{\phi_{ak}} \ln p(\phi_{ak} | \al) +
\sum_{b} g_{ab}(\phi_{ak})
\eea
where $g_{ab}(\phi_{ak}) = \fp{}{\phi_{ak}} \ln \sum_{z_{ab}, z_{ba}} p(y_{ab}, z_{ab}, z_{ba} | \bt , \phi_a, \phi_b)$ which can be written as 
\bea 
g_{ab}(\phi_{ak}) = \eE\left[ \f{\eI [z_{ab} = k]}{ \phi_{ak}} - \f{1}{\phi_{a\cdot}} \right].
\label{eqn:grad_local}
\eea
Here the expectation is w.r.t. the distribution in Eq.~\eqref{eqn:case}. To compute the expectation analytically, we first integrate out $z_{ba}$ from Eq.~\eqref{eqn:case} because the expectation depends only on $z_{ab}$, and obtain the following probability up to a normalization constant

\begin{align}
&f_{ab}^{(y)}(k) = \sum_{l=1}^K f_{ab}^{(y)}(k,l)\nonumber \\ =& \pi_{ak}
\left\{ \bt_k^{y}(1-\bt_k)^{(1-y)} \pi_{bk} + \dt^{y}(1-\dt)^{(1-y)} (1- \pi_{bk}) \right\}.\label{eqn:local_f}
\end{align}

Then we obtain the normalization term by $Z_{ab}^{(y)} = \sm{k}{K}f_{ab}^{(y)}(k)$. 
Integrating out the expectation in Eq.~\eqref{eqn:grad_local}, we obtain 
\bea
g_{ab}(\phi_{ak}) = \f{f_{ab}^{(y)}(k)}{Z_{ab}^{(y)}\phi_{ak}} - \f{1}{\phi_a}.
\eea 
Plugging this to Eq.~\ref{eqn:sgrld_update}, we obtain the SGRLD update rule for the local parameter $\phi_{ak}$
\bea
\phi_{ak}^* \law \left| \phi_{ak} + \f{\ep}{2} \left( \al - \phi_{ak} + \f{N}{|\Neighbors|} \sum_{b \in \Neighbors} g_{ab}(\phi_{ak})\right) \right. \nn \\ \left. + (\phi_{ak})^{\ha} \xi_{ak}\right|.\label{eqn:local_update}
\eea
Here, the $\Neighbors$ is the neighbor set for a mini-batch node, another random mini-batch of $n$ nodes sampled from \Vertices or $E$. Note that $|\Neighbors| \ll |\Vertices|=N$.

\end{comment}

\subsection{Related work on parallel community detection}

Among previous work on parallelizing MMSB algorithms, we mention the Online
Tensor approach~\cite{DBLP:journals/corr/HuangNHVA13} on GPUs, and our previous
parallel implementation of SG-MCMC on GPUs and multi-core CPUs (submitted for
publication). There are a few projects that did a distributed implementation
for community detection on very large network graphs. In contrast to our work,
they all detect non-overlapping communities: \cite{Bu2013246} investigate a
large number of networks; \cite{2015arXiv150302115L} investigate hierarchical
stochastic blockmodels; \cite{Prat-Perez:2014:HQS:2566486.2568010} use
multi-core machines.

\begin{comment}
In this paper, we describe our custom RDMA D-KV (Distributed Key-Value)
store. Current RMDA D-KV store implementations are RamCloud~\cite{RamCloud},
Pilaf~\cite{Pilaf}, Herd~\cite{Herd} and FaRM~\cite{FaRM}. All these systems
use RDMA to implement a D-KV store. However, all of them are far more powerful
than our custom implementation -- and this power comes at a cost that we
can avoid. They implement a generic D-KV store that controls concurrency,
supports dynamic inserts and deletes, supports variable-sized values
(whose size may change at an update), and keys of arbitrary type. Because
of the nature of our distributed algorithm, we have to deal with none of
these issues. For us, values are fixed-size, allocated only at the initial
population, and remain alive forever. We have no concurrency between writes
and reads or other writes. Our keys are a contiguous range of integers. All
these properties together allow an extremely low-overhead implementation
that does not involve the remote host in any transaction.
\end{comment}
