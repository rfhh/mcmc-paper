The MCMC-aMMSB algorithm that is the subject of this paper was initially
implemented in Python~\cite{LiAW15}, as is common
in the machine learning community.
We converted this implementation into an efficient sequential C++ application
to serve as a baseline for the parallel and distributed implementations that
are the subject of the rest of this paper.
We certainly do not consider this sequential implementation to be a contribution to the parallelization
of the algorithm, but for a fair analysis of the parallel implementations
a good baseline is necessary.

The Python implementation
relied on Numpy~\cite{numpy} to perform numerical computations efficiently.
Besides, the algorithm
made heavy use of Python data structures such as sets, dictionaries and
lists, which have no efficient Numpy equivalent.

First, the Python code base was ported into equivalent C++ code.
The program structure remained unchanged and the Python data structures were
substituted with their direct C++ alternatives.
%
The next step was to remove a number of inefficiencies.
For example, one recurring idiom in the Python implementation
was a choice expression of the form $a^y b^{1-y}$, where $y$ is either 0 or~1.
% Therefore, the expression is simply a choice
% between $a$ for $y=1$ and $b$ for $y=0$. However, as the compiler cannot infer
% the value of $y$, both expressions $a$ and $b$ were computed and their
% resulting values were raised to the power $y$ and $1-y$ respectively.
We transformed such expressions into conditional expressions which
compute either $a$ or $b$, and avoid floating-point exponentiation.
%
% Similarly, we transformed some expressions to a more efficient form.
% For example, we replaced expressions of the form $a^{0.5}\times{b}^{0.5}$
% with $sqrt(ab)$.
Other optimizations were loop strength
reduction and common subexpression lifting.
%
% In summary, a multitude of localized optimizations were applied to achieve
% an efficient sequential baseline version, which is 1000..1500 times faster
% than the original Python code, see the next Section.
All transformations were rigorously tested to ensure they do
not modify the behavior of the algorithm.
%
\begin{comment}
Further, we replaced calls to the system's random
functions with a custom implementation of the random generator
\textit{xorshift\_128}~\cite{Marsaglia:2003:XR}. This way, random calls no longer
involve system calls, so we can support easy and fast multi-threaded random
calls by providing each thread with its private, differently seeded, random
generator.
\end{comment}
