\begin{comment}
3. evaluation
   - do we speak again about sampler strategies? no need, I think, or a
     one-liner that we use the best strategy from above, and did very short
     evaluation with large data set
   - measurements:
     + Friendster:
       - sweep over K and discuss
     + dblp???? soc-lj????
       - sweep over K and discuss
       - sweep over np and discuss
   - discuss time breakdown (need some terminated runs):
     + dblp
     + Friendster
     points to discuss:
     + update phi: compute time vs memory access time
     + update pi: idem, compare to update phi
     + update beta: idem, compare to update phi
     + perplexity: idem, compare to update phi

\end{comment}

\subsection{Distributed-memory evaluation}

The implementation started out using the std::unordered\_set in the C++
standard library as the datastructure to store $G$, $H$, the held-out set,
and test set. For the large networks like Friendster, this led to immediate
storage problems. The std::unordered\_set in gcc's implementation uses
between 24 and 32 extra bytes of storage per item~\cite{g++ unordered_set
memory overhead}, while a vertex in $G$ is represented by a 4-byte integer,
a 6 to 8-fold penalty. We switched our set implementation to use Google's
sparse-hash-set implementation~\cite{google-sparse-hash}, which has in the
order of~1\% space overhead. This set implementation is reported to be slower,
but in our application, the extra time was not measurable.

The evaluation of the distributed implementation of the MCMC a-MMSB solver
focuses on very large networks.

Use the best sampler strategy, RNL/Sx/BF

\subsubsection{Scalability over the number of machines}

Using dblp with -K 1K, -m 1K, -n 256:
\begin{itemize}
\item Compare sequential performance penalty against sequential C++ impl. and
	against OpenCL impl
\item analyze the time to load $\pi$ vs. compute time, for update\_phi and
	cal\_perplexity; check whether np is relevant; also check how $N*K/np$
	is relevant, using multiple networks (dblp, youtube, soc-lj)
\item sweep over np
\end{itemize}

\subsubsection{Scalability over the number of communities}

Present the Friendster data, incl some analysis: upsweep for K=256
