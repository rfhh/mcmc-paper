\section{Conclusions}
\label{sec-conclusion}

Modern machine learning algorithms are empowering their
users to solve or approximate solutions to previously intractable problems.
However, these advancements come at the cost of significant computational
complexity and long running learning processes which hinder our ability to reap
such algorithms' benefits when applied to large problems. There is a clear need
to assess such algorithms and identify optimization opportunities in order to
scale their performance.

The SG-MCMC algorithm discussed in this paper posed additional computational
challenges due to its unique stochastic nature and \emph{high data intensity}. Unlike
common machine learning algorithms, its data dependencies and memory access
patterns are \emph{nondeterministic}. In this paper, we presented our methodology of
improving the algorithm's performance by restructuring it to
cater for concurrent and distributed parallelism.

After a thorough
analysis of the computational patterns and data structures,
we showed that the algorithm's state can be reduced by 75\%,
thus significantly
reducing its data intensity.

In our implementation for accelerators, we navigated the complex optimization
landscape by dynamically generating kernel code for finest control of allocation in
the GPU memory hierarchy, and by tuning parameters like kernel block size and vector
width. These efforts resulted in
a significant speedup of 120$\times$ on a GPU.
This speedup is achieved in comparison to an already
optimized sequential implementation. The evaluation of the performance
across several GPUs yielded one striking find. No single optimization strategy
works best for all GPUs: different choices for memory allocation strategy,
kernel block size and vector width were required for optimal results for
different GPUs and problem instances. Counter-intuitively, some GPUs performed
best with vectorization disabled.
%
The outcome of this study therefore reinforces the significance of avoiding premature
optimization. In particular, the success
of common GPU optimizations depends on the device and the
problem size it is applied to.

We further created a highly scalable implementation to handle the largest existing
community graphs on a distributed cluster machine. The most important data structures
are partitioned across the collective memory of the cluster nodes, which
significantly hurts data access latency and bandwidth for our already data-dominant algorithm.
We made several contributions to improve performance and still maintain scalability:
we created a custom distributed Key-Value store implemented with high-speed RDMA
primitives, that exploits the algorithm's structure to avoid concurrency issues; we
use MPI for synchronization and work distribution between the master and worker nodes;
and
we overlapped computation
with communication to hide latency.
%
By evaluating the system empirically using 65 cluster nodes and large data sets,
we show that its strong and weak scalability are both good. We also compared its
performance against a 40-core shared-memory system with 1TB of memory.
The distributed system has far stronger performance because it has more cores and
more collective memory bandwidth, even though it must fetch its data through the network.
% Additionally, we assessed the efficiency of the algorithm's resource utilization.
Finally, a
demonstration of the implementation's utility was provided by processing 6
large real-world data sets.
To the best of
our knowledge, this is the first time that the problem of deducing overlapping
communities has been learned for problems of such a large scale.
