\section{Introduction}
The tremendous amount of data that we generate through our daily applications such as social networking services, online shopping, and news recommendations, provides us with an opportunity to extract hidden but useful, even invaluable information. Realizing this opportunity, however, requires a significant amount of effort because traditional machine learning algorithms often become extremely inefficient with large amounts of data.

There have been two main approaches to resolving this issue; machine learning researchers have developed new scalable algorithms~\cite{bottou2010large, boyd2011distributed}, while systems and networking researchers have worked on developing new generic infrastructure systems which can be leveraged to construct machine learning solutions more efficiently~\cite{dean2008mapreduce, chang2008bigtable}.
However, the best possible performance is often achieved by carefully integrating both of these approaches in a single solution.

One such big data problem is analyzing large graphs such as social networks where it is not unusual to see a network consisting of billions of edges and tens of million of vertices~\cite{yang2015defining}. In particular, we are interested in the overlapping community detection problem~\cite{xie2013overlapping}, where the goal is to learn the probability distribution of each vertex to participate in each community, given a set of vertices, the links between them (which are usually very sparse), and the number of latent communities. A community can be seen as a densely connected group of vertices that are only sparsely connected to the rest of the network. This problem is significantly more complex than the related domain of detecting disjoint communities.

The problem of detecting overlapping communities is modeled by the mixed membership stochastic block model (MMSB)~\cite{airoldi2009mixed} and in this paper we are particularly interested in a variant of MMSB, called assortative MMSB (a-MMSB\footnote{Although we work on a-MMSB for simplicity, it is also straightforward to apply the proposed method to the general MMSB model.}) \cite{gopalan2012scalable}.
The MMSB model is a probabilistic graphical model~\cite{koller2009probabilistic} that represents a convenient paradigm for modeling complex relationships between a potentially large number of random variables. Bayesian graphical models, where we define priors and infer posteriors over parameters, also allow us to quantify model uncertainty and facilitate model selection and averaging. However, an increasingly urgent question is whether these models and their inference procedures will be up to the challenge of handling very large graphs.

There have been two main recent advances in this direction of scalable Bayesian inference: methods based on stochastic variational Bayes (SVB)~\cite{gopalan2012scalable,hoffman2013stochastic,gopalan2013efficient} and stochastic gradient Markov chain Monte Carlo (SG-MCMC)~\cite{welling2011bayesian,patterson2013stochastic,ahn2014distributed,ahn2012bayesian}. Both methods have the important property that they only require a small subset of the data for every iteration. In other words, they can be applied to (infinite) streaming data.

In this paper, we focus on the SG-MCMC method applied to the a-MMSB model. Recent
work~\cite{LiAW15} showed that this methodology is faster and more accurate than the
SVB method. \cite{LiAW15} further proposes a heuristic to scale up the number of
communities at the cost of less precision; the work in this paper considers the
algorithm without that heuristic.

From a computational point of view, our SG-MCMC a-MMSB algorithm differs
from widespread machine learning algorithms, like deep learning, in several
ways. First, it is highly data-intensive which makes parallel acceleration
particularly challenging. Second, owing to the algorithm's stochastic
nature, the majority of its memory access patterns and data dependencies
are non-deterministic. As a result, straightforward optimization attempts
of the memory access patterns either fail or lead to non-intuitive results. Third,
the size of its intermediate data structures makes it difficult to scale to very large
community graphs.

Starting from an existing implementation in Python/Numpy, we will present
how this algorithm can be implemented much more efficiently in C++. Then,
we will describe our two key contributions: first, how to scale up our
implementation to run on GPUs and multicore CPUs, second, to scale out
our implementation to overcome the memory bounds posed by GPUs or
single-machine systems in general.
% To this end, we propose a design of a parallel and distributed system specifically tailored to solve the a-MMSB problem. In particular, we use a mixture of OpenMP, MPI and RDMA in order to efficiently scale and accelerate the algorithm's computation.

The focus of the first part of our work is on the computational efficiency and parallel
performance of the SG-MCMC algorithm by
developing aggressive optimizations targeting
multi-core CPUs and GPUs. The GPU implementation achieves speedup factors up to~86,
compared to the
well-tuned sequential C++ program which itself is a factor~1000-1500 faster than
the original Python/Numpy program.
%
Through careful analysis of the computation and data structures we show that
the algorithm's full state can be reduced by roughly 75\%. Compressing the
state significantly reduces the data intensity and allows for tackling larger
problems. % while maintaining all state in memory.

\begin{comment}
Further, by cataloguing and accounting for the various load and store
operations, we identified the highest priority locations of data reuse. In
order to circumvent the unclear optimization landscape, we developed an
effective kernel code generation mechanism that explores the benefits of
exploiting all permutations of the available optimization opportunities. These
optimizations include caching in shared memory, caching in the register file,
loop unrolling and explicit vectorization.
\end{comment}

The second part of our work, scaling out to the largest publicly available
community graphs, also necessitated overcoming several challenges.
The algorithm's state grows rapidly with larger graphs and number of latent
communities.  Since the full state for the larger graphs does not fit in a
single machine's memory, it is partitioned and distributed across a cluster
of machines. Hence, to access the full state, each cluster node must read
remote memory hosted by its peers. We leveraged RDMA to improve the latency and
bandwidth
of such operations. To reduce the
latency further, we pipelined the algorithm's computations by fetching
data in advance over the network.
\begin{comment} Finally, the algorithm's computation
is effectively distributed across the cluster nodes and parallelized further
within each node by exploiting their multi-core CPUs.
\end{comment}

The remainder of this paper is organized as follows.
Section~\ref{sec-background} provides an overview of the
algorithm and its theoretical foundation, with related work in
Section~\ref{sec-related}. Section~\ref{sec-gpu} delves
into the parallelization optimizations for GPUs and multicore CPUs.
Section~\ref{sec-distr} describes the design, implementation and evaluation of
the scalable distributed solution. Finally, Section~\ref{sec-conclusion}
provides concluding remarks.

% -------\\
% Community detection is the central problem in network analysis, with the goal of identifying the groups of related nodes that are densely connected within this group but sparsely connected to the rest of the network. Different from classical community detection problem where we assume each node belongs to one single community, our paper considers overlapping communities where each of the nodes might belong to multiple communities. In particular, we consider the model called a-MMSB(Assortive Mixed Membership Stochastic Blockmodel) in this paper, which was first introduced in~\cite{gopalan2012scalable}.\\


% a-MMSB, as a probabilistic graphical model, represents a convenient paradigm for modeling complex relationships between a potentially large number of random variables. It also uses priors and posteriors to quantify model uncertainty and facilitate model selection and averaging. While a-MMSB provides rich representation power, like other Bayesian models, the inference procedures of handling big data which is common in real world is still a very challenging problem. \\



% Consider the large networks such as a social network, it easily runs into billions of edges and tens of million of nodes. In addition to that, the number of communities might exceed few millions. 
% There were two types of scalable algorithm for a-MMSB have been introduced recently \cite{gopalan2012scalable}, stochastic variational Bayesian inference (SVB) and stochastic gradient Markov chain Monte Carlo(SG-MCMC), respectively. Both methods have the important property that each iteration only relies on a small subset of the data. Although both methods can work for some large networks with many hundreds of nodes, the performance is far less satisfactory when it applies to the so-called "big data" such as facebook network with millions of nodes and billions of edges. Given the facts that \cite{LiAW15}, SG-MCMC runs faster and converges to the better local minima, in this paper, we mainly consider the problem of scaling up SG-MCMC to the big data set.  \textit{As far as we know, this is the first paper that studies community detection on the frencter dataset with few billion's of edges.}




